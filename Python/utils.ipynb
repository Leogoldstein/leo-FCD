{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e427ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.transforms as tfs\n",
    "from scipy.signal import wiener\n",
    "import collections\n",
    "from scipy import stats\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import json  \n",
    "import os\n",
    "import seaborn as sns\n",
    "import scikit_posthocs as sp\n",
    "from IPython.display import clear_output\n",
    "import networkx as nx\n",
    "from bct.utils import BCTParamError, normalize, get_rng\n",
    "\n",
    "import warnings\n",
    "import matplotlib\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram,fcluster\n",
    "from statsmodels.sandbox.stats.runs import runstest_1samp \n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "from pyrqa.time_series import TimeSeries\n",
    "from pyrqa.settings import Settings\n",
    "from pyrqa.analysis_type import Classic\n",
    "from pyrqa.neighbourhood import FixedRadius, RadiusCorridor\n",
    "from pyrqa.metric import EuclideanMetric, MaximumMetric, TaxicabMetric\n",
    "from pyrqa.computation import RQAComputation\n",
    "from pyrqa.computation import RPComputation\n",
    "from pyrqa.image_generator import ImageGenerator\n",
    "import umap\n",
    "from pyrqa.neighbourhood import Unthresholded\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984abd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rate(raster,ci,c,bin_=4,fps=4,r=1.5):\n",
    "    N,F=raster.shape\n",
    "    indices_ci=np.where(ci==c)[0]\n",
    "    raster_cluster=raster[indices_ci,:]\n",
    "    y=np.sum(raster_cluster,axis=0)\n",
    "    rate=np.zeros(y.shape)\n",
    "    bin_b=0\n",
    "    for j in range(y.shape[0]):\n",
    "        rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "        if bin_b<bin_:\n",
    "            bin_b+=1\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "    fig=plt.figure(figsize=(12,3))\n",
    "    #ax=plt.axes((0.05,0.35,0.75,0.9))\n",
    "    plt.plot(x,rate,color='black')\n",
    "    plt.xlim(np.min(x),np.max(x))\n",
    "    plt.ylim(0,np.max(rate)+1)\n",
    "    rate[np.where(rate==0)[0]]=np.nan\n",
    "    time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "    settings = Settings(time_series,\n",
    "                    analysis_type=Classic,\n",
    "                    neighbourhood=FixedRadius(r),    \n",
    "                    #neighbourhood=Unthresholded(),\n",
    "                    similarity_measure=EuclideanMetric,\n",
    "                    theiler_corrector=1)\n",
    "    computation = RPComputation.create(settings)\n",
    "    result = computation.run()\n",
    "    return result.recurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ef45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recurrence_analysis(raster,ci,r=1.5,bin_=4):\n",
    "    df=pd.DataFrame(columns=['Ensemble','N','RR','DET','L','L_max','DIV','L_entr','LAM','TT','V_max','V_entr','W','W_max','W_div','W_entr'])\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        y=np.sum(raster_cluster,axis=0)\n",
    "        rate=np.zeros(y.shape)\n",
    "        bin_b=0\n",
    "        for j in range(y.shape[0]):\n",
    "            rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "            if bin_b<bin_:\n",
    "                bin_b+=1\n",
    "        rate[np.where(rate==0)[0]]=np.nan\n",
    "        time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "\n",
    "        settings = Settings(time_series,\n",
    "                            analysis_type=Classic,\n",
    "                            neighbourhood=FixedRadius(r),\n",
    "                            similarity_measure=EuclideanMetric,\n",
    "                            theiler_corrector=1)\n",
    "        computation = RQAComputation.create(settings,\n",
    "                                        verbose=True)\n",
    "\n",
    "        result = computation.run()\n",
    "        result.min_diagonal_line_length = 2\n",
    "        result.min_vertical_line_length = 2\n",
    "        result.min_white_vertical_line_length = 2\n",
    "        fila={'Ensemble':i,'N':len(indices_ci),\n",
    "              'RR':result.recurrence_rate,'DET':result.determinism,\n",
    "              'L':result.average_diagonal_line,'L_max':result.longest_diagonal_line,'DIV':result.divergence,\n",
    "              'L_entr':result.entropy_diagonal_lines,'LAM':result.laminarity,\n",
    "              'TT':result.laminarity,'V_max':result.longest_vertical_line,\n",
    "              'V_entr':result.entropy_vertical_lines,'W':result.average_white_vertical_line,\n",
    "              'W_max':result.longest_white_vertical_line,'W_div':result.longest_white_vertical_line_inverse,\n",
    "              'W_entr':result.entropy_white_vertical_lines}\n",
    "        df=df.append(fila, ignore_index=True)\n",
    "        clear_output()\n",
    "    v_max=1\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        y=np.sum(raster_cluster,axis=0)\n",
    "        rate=np.zeros(y.shape)\n",
    "        bin_b=0\n",
    "        for j in range(y.shape[0]):\n",
    "            rate[j]=np.sum(y[j-bin_b:j+1])\n",
    "            if bin_b<bin_:\n",
    "                bin_b+=1\n",
    "        rate[np.where(rate==0)[0]]=np.nan\n",
    "        time_series = TimeSeries(rate,embedding_dimension=2,time_delay=1)\n",
    "        settings = Settings(time_series,\n",
    "                        analysis_type=Classic,\n",
    "                        neighbourhood=FixedRadius(r),    \n",
    "                        #neighbourhood=Unthresholded(),\n",
    "                        similarity_measure=EuclideanMetric,\n",
    "                        theiler_corrector=1)\n",
    "        computation = RPComputation.create(settings)\n",
    "        result = computation.run()\n",
    "        plt.matshow(result.recurrence_matrix,cmap='Blues',vmin=0, vmax=v_max)\n",
    "        plt.colorbar()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fbf638",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_graph(transition_matrix,cmap):\n",
    "    G = nx.DiGraph()\n",
    "    color_map=[]\n",
    "    for i in range(len(transition_matrix)):\n",
    "        G.add_node(i)\n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            color_map.append(cmap(i/(len(transition_matrix)-1)))\n",
    "        else:\n",
    "            color_map.append(cmap(i))\n",
    "    for i in range(len(transition_matrix)):\n",
    "        for j in range(len(transition_matrix)):\n",
    "            if transition_matrix[i,j]>=1:\n",
    "                if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                    G.add_edge(i,j, weight=transition_matrix[i,j],color=cmap(i/(len(transition_matrix)-1))) \n",
    "                else:\n",
    "                    G.add_edge(i,j, weight=transition_matrix[i,j],color=cmap(i))    \n",
    "    return G,color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6396acef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transition_matrix(colores,ci):\n",
    "    secuencia=[-1]\n",
    "    for key,values in colores.items():\n",
    "        if len(values)>=1:\n",
    "            for value in values:\n",
    "                if secuencia[-1]!=value:\n",
    "                    secuencia.append(value)\n",
    "                    break\n",
    "    del secuencia[0]\n",
    "    transition_matrix=np.zeros((max(secuencia)+1,max(secuencia)+1))\n",
    "    for i in range(len(secuencia)-1):\n",
    "        transition_matrix[secuencia[i],secuencia[i+1]]+=1\n",
    "    for i in range(max(ci)+1):\n",
    "        #transition_matrix[i,:]=(transition_matrix[i,:]/np.sum(transition_matrix[i,:]))*100\n",
    "        transition_matrix[i,:]=(transition_matrix[i,:]/np.sum(transition_matrix))*100\n",
    "    return transition_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3D_projection_vectors(raster,ci,n_cmap,window_percentage,n_sigma,min_dist,random_state,metric):\n",
    "    #%matplotlib notebook\n",
    "    cmap = matplotlib.cm.get_cmap(n_cmap)  \n",
    "    colores={}\n",
    "    for i in range(raster.shape[1]):\n",
    "        colores[i]=[]\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]    \n",
    "        peaks,th=get_tam_pico_sig(raster_cluster,window_percentage,n_sigma)\n",
    "        for j,pk in enumerate(peaks):\n",
    "            if pk:\n",
    "                colores[j].append(i)\n",
    "    raster_ensemble=np.empty((raster.shape[0],0), int)\n",
    "    color_to_plot=[]\n",
    "    count=0\n",
    "    for i in range(raster.shape[1]):\n",
    "        list_=colores[i]\n",
    "        if len(list_)>0:\n",
    "            for item in list_:\n",
    "                raster_ensemble=np.append(raster_ensemble, np.expand_dims(raster[:,i], axis=1), axis=1)\n",
    "                raster_ensemble[np.where(ci!=item)[0],count]=0\n",
    "                color_to_plot.append(item)\n",
    "                count+=1            \n",
    "    \n",
    "    mapper = umap.UMAP(min_dist=min_dist,n_components=3,random_state=random_state,metric=metric).fit(raster_ensemble.T)\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in range(raster_ensemble.shape[1]):\n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1],mapper.embedding_[i, 2],\n",
    "                       s=15, color=cmap(color_to_plot[i]/max(color_to_plot)))\n",
    "        else:\n",
    "            ax.scatter(mapper.embedding_[i, 0], mapper.embedding_[i, 1],mapper.embedding_[i, 2],\n",
    "                       s=15, color=cmap(color_to_plot[i]))\n",
    "    \n",
    "    return mapper,color_to_plot,colores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensamble_raster(raster,fps,cluster_index,name_colormap,n_sigma=2,window_percentage=20,markersize=5):\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    actividad=np.zeros((N,1))\n",
    "    orden_plot=[]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6))\n",
    "    count=0\n",
    "    ensembles_in_time={}\n",
    "    for i in range(raster.shape[1]):\n",
    "        ensembles_in_time[i]=[]\n",
    "    \n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        indices_ci=np.where(cluster_index==ci)[0]\n",
    "        coactividad_cluster=np.sum(raster[np.where(cluster_index==ci)[0],:],axis=0)\n",
    "        peaks,th=get_tam_pico_sig(raster[np.where(cluster_index==ci)[0],:],window_percentage,n_sigma)\n",
    "        \n",
    "        idx=np.where(peaks==True)[0]\n",
    "        for i in indices_ci:\n",
    "            orden_plot.append(i)\n",
    "            indices=np.where(raster[i,:]==1)[0]\n",
    "            \n",
    "            if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci/max(cluster_index)),alpha=0.1)\n",
    "                plt.plot(idx,raster[i,idx]*(count+1),\n",
    "                        marker='s',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci/max(cluster_index)),alpha=1)\n",
    "            else:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=0.1)\n",
    "                plt.plot(idx,raster[i,idx]*(count+1),\n",
    "                        marker='s',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci),alpha=1)\n",
    "            actividad[count]=np.sum(raster[i,:])*100/F\n",
    "            count+=1\n",
    "        \n",
    "        for j,pk in enumerate(peaks):\n",
    "            if pk:\n",
    "                ensembles_in_time[j].append(ci)       \n",
    "        \n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Neuron Label\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "    plt.plot(tiempo,coactividad,linewidth=0.5,color='black',alpha=1)\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,ymax=np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"Coactivity\")\n",
    "    ymax=np.max(coactividad)+1\n",
    "    inicio=-1\n",
    "    final=-1\n",
    "    bin_=markersize+2\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        for key,value in ensembles_in_time.items():\n",
    "            encontre=False\n",
    "            if len(value)>0:\n",
    "                for ensemble in value:\n",
    "                    if ensemble==ci:\n",
    "                        encontre=True\n",
    "                        if inicio<0:\n",
    "                            inicio=key\n",
    "                            final=key\n",
    "                        else:\n",
    "                            final=key\n",
    "                        break\n",
    "                if encontre==False:\n",
    "                    if final>0:\n",
    "                        if inicio-bin_<0:\n",
    "                            if final+bin_>F:\n",
    "                                x=tiempo[0:F]\n",
    "                            else:\n",
    "                                x=tiempo[0:final+bin_]\n",
    "                        elif final+bin_>F:\n",
    "                            x=tiempo[inicio-bin_:F]\n",
    "                        else:\n",
    "                            x=tiempo[inicio-bin_:final+bin_]\n",
    "                        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                            plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci/max(cluster_index)),alpha=0.5)\n",
    "                        else:\n",
    "                            plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci),alpha=0.5)\n",
    "                        inicio=-1\n",
    "                        final=-1\n",
    "            if encontre==False:\n",
    "                if final>0:\n",
    "                    if inicio-bin_<0:\n",
    "                        if final+bin_>F:\n",
    "                            x=tiempo[0:F]\n",
    "                        else:\n",
    "                            x=tiempo[0:final+bin_]\n",
    "                    elif final+bin_>F:\n",
    "                        x=tiempo[inicio-bin_:F]\n",
    "                    else:\n",
    "                        x=tiempo[inicio-bin_:final+bin_]\n",
    "                    if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                        plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci/max(cluster_index)),alpha=0.5)\n",
    "                    else:\n",
    "                        plt.fill_between(x, np.ones(x.shape)*ymax, np.zeros(x.shape),facecolor=cmap(ci),alpha=0.5)\n",
    "                    inicio=-1\n",
    "                    final=-1\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"# Frames\")\n",
    "    plt.yticks([])\n",
    "    return orden_plot,ensembles_in_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e460ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coactivity_is_random(raster,ci,n_iter):\n",
    "    for i in range(max(ci)+1):\n",
    "        indices_ci=np.where(ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        print('Cluster',i)\n",
    "        coactivity_is_random(raster_cluster,n_iter)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc9c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tam_pico_sig(raster,window_percentage=20,n_sigma=2):\n",
    "    column = np.sum(raster,axis=0)\n",
    "    N = len(column)\n",
    "    time = np.arange(0,N)\n",
    "    k = int(len(column) * (window_percentage/100))\n",
    "    get_bands = lambda column : (np.mean(column) + n_sigma*np.std(column),np.mean(column) - n_sigma*np.std(column))\n",
    "    bands = [get_bands(column[range(0 if i - k < 0 else i-k ,i + k if i + k < N else N)]) for i in range(0,N)]\n",
    "    upper, lower = zip(*bands)\n",
    "    anomalies = (column > upper) | (column < lower)\n",
    "    \n",
    "    for j in range(N):\n",
    "        if anomalies[j]==True:\n",
    "            if column[j]<2:\n",
    "                anomalies[j]=False\n",
    "    \n",
    "    return anomalies,upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54e3f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_coactivity_ensambles(raster,cluster_index,n_iter,name_colormap,fps,window_percentage=20,n_sigma=2):\n",
    "    Ci=cluster_index\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    nmodules=max(Ci)+1\n",
    "    maxCo=0\n",
    "\n",
    "    for i in range(int(nmodules)):\n",
    "        tempCo=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        if max(tempCo)>maxCo:\n",
    "            maxCo=max(tempCo)\n",
    "\n",
    "    fpm=fps*60\n",
    "    x=np.arange(0,F)/fpm\n",
    "\n",
    "    Co=np.zeros((int(nmodules),len(tempCo)))\n",
    "\n",
    "    fig=plt.figure(figsize=(12,6))\n",
    "    #ax=plt.axes((0.05,0.35,0.75,0.9))\n",
    "    plt.subplots_adjust(hspace=0.000)\n",
    "    number_of_subplots=nmodules\n",
    "    ejes=[]\n",
    "    for i in range(int(nmodules)):\n",
    "        indices_ci=np.where(Ci==i)[0]\n",
    "        raster_cluster=raster[indices_ci,:]\n",
    "        peaks,th=get_tam_pico_sig(raster_cluster,window_percentage,n_sigma)     \n",
    "        Co[i,:]=np.sum(raster[np.where(Ci==i)[0],:],axis=0)\n",
    "        ax = plt.subplot(number_of_subplots,1,number_of_subplots-i)\n",
    "        \n",
    "        if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "            ax.plot(x,Co[i,:],color=cmap(i/max(Ci)),alpha=1)\n",
    "            ax.plot(x,th,color=cmap(i/max(Ci)),alpha=0.2)\n",
    "            plt.fill_between(x, th, np.zeros(x.shape),facecolor=cmap(i/max(Ci)),alpha=0.1)\n",
    "        else:        \n",
    "            ax.plot(x,Co[i,:],color=cmap(i),alpha=1)\n",
    "            ax.plot(x,th,color=cmap(i),alpha=0.2)\n",
    "            plt.fill_between(x, th, np.zeros(x.shape),facecolor=cmap(i),alpha=0.1)\n",
    "\n",
    "        ax.set_xlim(np.min(x),np.max(x))\n",
    "        ax.set_ylim(0,maxCo+1)\n",
    "        if i==0:\n",
    "            plt.xlabel(\"Time (min)\")\n",
    "            plt.ylabel(\"Coactivity\")\n",
    "        else:\n",
    "            ax.set_xticks([])\n",
    "        ejes.append(ax)\n",
    "\n",
    "    for ax in ejes:\n",
    "        pos=ax.get_position()\n",
    "        pos=pos.from_extents(0.05,pos.y0,0.8,pos.y1)\n",
    "        ax.set_position(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4d5633",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coactivity_is_random(raster,n_iter):\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    rt,p=runstest_1samp(coactividad,cutoff='mean',correction=False)\n",
    "    print('rt =',rt)\n",
    "    print('p =',p)\n",
    "    #type 1 error\n",
    "    Im=0\n",
    "    for i in range(n_iter):\n",
    "        raster_s=raster_subrogado(raster,1)\n",
    "        coactividad_s=np.sum(raster_s,axis=0)\n",
    "        rt_s,p_s=runstest_1samp(coactividad_s,cutoff='median',correction=False)\n",
    "        if p_s<=0.05:\n",
    "            Im+=1\n",
    "    alphahat=Im/n_iter\n",
    "    print('alphahat',alphahat)\n",
    "    #type 2 error\n",
    "    Im=0\n",
    "    for i in range(n_iter):\n",
    "        raster_s=raster_subrogado(raster,2)\n",
    "        coactividad_s=np.sum(raster_s,axis=0)\n",
    "        rt_s,p_s=runstest_1samp(coactividad_s,cutoff='median',correction=False)\n",
    "        if p_s>0.05:\n",
    "            Im+=1\n",
    "    betahat=Im/n_iter\n",
    "    print('betahat',betahat)\n",
    "    return rt,p,alphahat,betahat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def raster_subrogado(raster_real,selector):\n",
    "    N,F=raster_real.shape\n",
    "    raster_artificial=np.zeros((N,F))\n",
    "    if selector == 1: #Mantiene número de neuronas y tiempo\n",
    "        for i in range(N):\n",
    "            raster_artificial[i,:]=raster_real[i,np.random.permutation(F)]\n",
    "    elif selector == 2: #Mantiene ISI y tiempo\n",
    "        for i in range(N):\n",
    "            isi=np.diff(np.where(np.concatenate(([1],raster_real[i,:],[1]))==1)).flatten()\n",
    "            t_inicio=isi[0]\n",
    "            t_final=isi[-1]\n",
    "            isi=np.delete(isi,[0])\n",
    "            isi=np.delete(isi,len(isi)-1)\n",
    "            isi_permutado=isi[np.random.permutation(len(isi))]\n",
    "            t_prim_esp=np.random.randint(t_inicio+t_final)\n",
    "            t_activo=np.concatenate(([0],np.cumsum(isi_permutado)))\n",
    "            t_esp=t_activo+t_prim_esp-1\n",
    "            raster_artificial[i,t_esp]=1\n",
    "    return raster_artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cf0f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cluster_raster(raster,fps,cluster_index,name_colormap,markersize=5):\n",
    "    cmap = matplotlib.cm.get_cmap(name_colormap)\n",
    "    N,F=raster.shape\n",
    "    actividad=np.zeros((N,1))\n",
    "    orden_plot=[]\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6))\n",
    "    count=0\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        indices_ci=np.where(cluster_index==ci)[0]\n",
    "        for i in indices_ci:\n",
    "            orden_plot.append(i)\n",
    "            indices=np.where(raster[i,:]==1)[0]\n",
    "            if type(cmap)==matplotlib.colors.LinearSegmentedColormap:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci/max(cluster_index)))\n",
    "            else:\n",
    "                plt.plot(indices,raster[i,indices]*(count+1),\n",
    "                        marker='|',linestyle='None',\n",
    "                        markersize=markersize,color=cmap(ci))\n",
    "            actividad[count]=np.sum(raster[i,:])*100/F\n",
    "            count+=1\n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Neuron Label\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "\n",
    "    plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"Coactivity\")\n",
    "\n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"# Frames\")\n",
    "    plt.yticks([])\n",
    "    \n",
    "    return orden_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01ea600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gephi_graph(ma,cluster_index,th):\n",
    "    ma_reduced=threshold_proportional(ma, th)\n",
    "    G=nx.from_numpy_matrix(ma_reduced)\n",
    "    ensemble_attr_dict={}\n",
    "    color_attr_dict={}\n",
    "    cmap = matplotlib.cm.get_cmap('tab10')\n",
    "    for i,ci in enumerate(cluster_index):\n",
    "        ensemble_attr_dict[i]=str(ci)\n",
    "        v=list(cmap(ci)[0:3])\n",
    "        v=[vi*255 for vi in v]\n",
    "        l=len(str(v))-1\n",
    "        color_attr_dict[i]=str(v)[1:l]\n",
    "    nx.set_node_attributes(G, ensemble_attr_dict, \"ensemble\")\n",
    "    nx.set_node_attributes(G, color_attr_dict,\"color\")\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78f675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ordered_adj_matrix(ma,cluster_index):\n",
    "    ma_ordered=np.zeros(ma.shape)\n",
    "    count=0\n",
    "    new_order=[]\n",
    "    for ci in range(max(cluster_index)+1):\n",
    "        indices_ci=np.where(cluster_index==ci)[0]\n",
    "        for indice in indices_ci:\n",
    "            new_order.append(indice)\n",
    "            count+=1\n",
    "    for i in range(len(new_order)):\n",
    "        indices_i=np.where(ma[new_order[i],:]>0)[0]\n",
    "        for indice in indices_i:\n",
    "            ma_ordered[i,np.where(new_order==indice)[0]]=ma[new_order[i],indice]\n",
    "    return ma_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7a7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuevo_cluster_index(cluster_index,nuevo_orden):\n",
    "    try:\n",
    "        n=len(nuevo_orden)\n",
    "        newCluster_index=np.zeros((len(cluster_index),))\n",
    "        for i in range(max(cluster_index)+1):\n",
    "            indices=np.where(cluster_index==nuevo_orden[i])[0]\n",
    "            newCluster_index[indices]=int(i)\n",
    "        return newCluster_index.astype(int)\n",
    "    except ValueError:\n",
    "        print(ValueError)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eded716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_raster(raster,fps,umbral=None,markersize=5):\n",
    "    N,F=raster.shape\n",
    "    plt.figure(figsize=(12,6))\n",
    "\n",
    "    ax=plt.axes((0.05,0.35,0.75,0.6)) \n",
    "    for i in range(N):\n",
    "        indices=np.where(raster[i,:]==1)[0]\n",
    "        plt.plot(indices,raster[i,indices]*(i+1),\n",
    "                marker='|',linestyle='None',\n",
    "                markersize=markersize,color='black')\n",
    "    ax.set_xlim(0,F-1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xticks([])\n",
    "    plt.ylabel(\"Neuron Label\")\n",
    "\n",
    "    ax=plt.axes(((0.05,0.12,0.75,0.2)))\n",
    "    coactividad=np.sum(raster,axis=0)\n",
    "    fpm=fps*60\n",
    "    tiempo=np.arange(0,F)/fpm\n",
    "    plt.plot(tiempo,coactividad,linewidth=0.5,color='black')\n",
    "    ax.set_xlim(np.min(tiempo),np.max(tiempo))\n",
    "    ax.set_ylim(0,np.max(coactividad)+1)\n",
    "    plt.xlabel(\"Time (min)\")\n",
    "    plt.ylabel(\"Coactivity\")\n",
    "\n",
    "    ax=plt.axes((0.85,0.35,0.1,0.6))\n",
    "    actividad=np.sum(raster,axis=1)\n",
    "    plt.plot(actividad,np.arange(1,N+1),color='black',linewidth=1)\n",
    "    ax.set_xlim(0,max(actividad)+1)\n",
    "    ax.set_ylim(1,N)\n",
    "    plt.xlabel(\"# Frames\")\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d9195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adj_matrix(mapper):\n",
    "    ma=np.zeros(mapper.graph_.shape)\n",
    "    contador=0\n",
    "    for i in range(ma.shape[0]):\n",
    "        tam=mapper.graph_.indptr[i+1]-mapper.graph_.indptr[i]\n",
    "        ma[i,mapper.graph_.indices[contador:contador+tam]]=mapper.graph_.data[contador:contador+tam]\n",
    "        contador+=tam\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ecae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters_modularidad(grafo_ponderado,n_iter):\n",
    "    N=len(grafo_ponderado)\n",
    "    mat_mismo_grupo=np.zeros(grafo_ponderado.shape)\n",
    "    for i in range(n_iter):\n",
    "        cluster_index,_=community_louvain(grafo_ponderado,seed=42)\n",
    "        for neu in range(N):\n",
    "            module = cluster_index[neu]\n",
    "            index = np.where(cluster_index==module)[0]\n",
    "            mat_mismo_grupo[neu,index]+=1\n",
    "    for i in range(N):\n",
    "        mat_mismo_grupo[i,i]=0\n",
    "    cluster_index_h,_=community_louvain(mat_mismo_grupo,seed=42)    \n",
    "    cluster_index_h=cluster_index_h-1\n",
    "    print(\"Number of Ensembles: \",str(max(cluster_index_h)+1))\n",
    "    return cluster_index_h,mat_mismo_grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e67260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_medias_sem(parameter):\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Control'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Control'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Decorticated'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Decorticated'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Parkinson'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Parkinson'][parameter].sem()))\n",
    "    print('{:.3f}'.format(df[df['Condition']=='Dyskinesia'][parameter].mean()),'±','{:.3f}'.format(2*df[df['Condition']=='Dyskinesia'][parameter].sem()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8dbaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teachers_round(x):\n",
    "    '''\n",
    "    Do rounding such that .5 always rounds to 1, and not bankers rounding.\n",
    "    This is for compatibility with matlab functions, and ease of testing.\n",
    "    Authors:\n",
    "        Olaf Sporns\n",
    "        Mikail Rubinov\n",
    "        Yusuke Adachi\n",
    "        Andrea Avena\n",
    "        Danielle Bassett\n",
    "        Richard Betzel\n",
    "        Joaquin Goni\n",
    "        Alexandros Goulas\n",
    "        Patric Hagmann\n",
    "        Christopher Honey\n",
    "        Martijn van den Heuvel\n",
    "        Rolf Kotter\n",
    "        Jonathan Power\n",
    "        Murray Shanahan\n",
    "        Andrew Zalesky\n",
    "    '''\n",
    "    if ((x > 0) and (x % 1 >= 0.5)) or ((x < 0) and (x % 1 > 0.5)):\n",
    "        return int(np.ceil(x))\n",
    "    else:\n",
    "        return int(np.floor(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdf1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def community_louvain(W, gamma=1, ci=None, B='modularity', seed=None):\n",
    "    '''\n",
    "    The optimal community structure is a subdivision of the network into\n",
    "    nonoverlapping groups of nodes which maximizes the number of within-group\n",
    "    edges and minimizes the number of between-group edges.\n",
    "    This function is a fast an accurate multi-iterative generalization of the\n",
    "    louvain community detection algorithm. This function subsumes and improves\n",
    "    upon modularity_[louvain,finetune]_[und,dir]() and additionally allows to\n",
    "    optimize other objective functions (includes built-in Potts Model i\n",
    "    Hamiltonian, allows for custom objective-function matrices).\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : NxN np.array\n",
    "        directed/undirected weighted/binary adjacency matrix\n",
    "    gamma : float\n",
    "        resolution parameter. default value=1. Values 0 <= gamma < 1 detect\n",
    "        larger modules while gamma > 1 detects smaller modules.\n",
    "        ignored if an objective function matrix is specified.\n",
    "    ci : Nx1 np.arraylike\n",
    "        initial community affiliation vector. default value=None\n",
    "    B : str | NxN np.arraylike\n",
    "        string describing objective function type, or provides a custom\n",
    "        NxN objective-function matrix. builtin values \n",
    "            'modularity' uses Q-metric as objective function\n",
    "            'potts' uses Potts model Hamiltonian.\n",
    "            'negative_sym' symmetric treatment of negative weights\n",
    "            'negative_asym' asymmetric treatment of negative weights\n",
    "    seed : hashable, optional\n",
    "        If None (default), use the np.random's global random state to generate random numbers.\n",
    "        Otherwise, use a new np.random.RandomState instance seeded with the given value.\n",
    "    Returns\n",
    "    -------\n",
    "    ci : Nx1 np.array\n",
    "        final community structure\n",
    "    q : float\n",
    "        optimized q-statistic (modularity only)\n",
    "    \n",
    "    Authors:\n",
    "        Olaf Sporns\n",
    "        Mikail Rubinov\n",
    "        Yusuke Adachi\n",
    "        Andrea Avena\n",
    "        Danielle Bassett\n",
    "        Richard Betzel\n",
    "        Joaquin Goni\n",
    "        Alexandros Goulas\n",
    "        Patric Hagmann\n",
    "        Christopher Honey\n",
    "        Martijn van den Heuvel\n",
    "        Rolf Kotter\n",
    "        Jonathan Power\n",
    "        Murray Shanahan\n",
    "        Andrew Zalesky\n",
    "    '''\n",
    "    rng = get_rng(seed)\n",
    "    n = len(W)\n",
    "    s = np.sum(W)\n",
    "\n",
    "    #if np.min(W) < -1e-10:\n",
    "    #    raise BCTParamError('adjmat must not contain negative weights')\n",
    "\n",
    "    if ci is None:\n",
    "        ci = np.arange(n) + 1\n",
    "    else:\n",
    "        if len(ci) != n:\n",
    "            raise BCTParamError('initial ci vector size must equal N')\n",
    "        _, ci = np.unique(ci, return_inverse=True)\n",
    "        ci += 1\n",
    "    Mb = ci.copy()\n",
    "    renormalize = False\n",
    "    if B in ('negative_sym', 'negative_asym'):\n",
    "        renormalize = True\n",
    "        W0 = W * (W > 0)\n",
    "        s0 = np.sum(W0)\n",
    "        B0 = W0 - gamma * np.outer(np.sum(W0, axis=1), np.sum(W0, axis=0)) / s0\n",
    "\n",
    "        W1 = -W * (W < 0)\n",
    "        s1 = np.sum(W1)\n",
    "        if s1:\n",
    "            B1 = W1 - gamma * np.outer(np.sum(W1, axis=1), np.sum(W1, axis=0)) / s1\n",
    "        else:\n",
    "            B1 = 0\n",
    "\n",
    "    elif np.min(W) < -1e-10:\n",
    "        raise BCTParamError(\"Input connection matrix contains negative \"\n",
    "            'weights but objective function dealing with negative weights '\n",
    "            'was not selected')\n",
    "\n",
    "    if B == 'potts' and np.any(np.logical_not(np.logical_or(W == 0, W == 1))):\n",
    "        raise BCTParamError('Potts hamiltonian requires binary input matrix')\n",
    "\n",
    "    if B == 'modularity':\n",
    "        B = W - gamma * np.outer(np.sum(W, axis=1), np.sum(W, axis=0)) / s\n",
    "    elif B == 'potts':\n",
    "        B = W - gamma * np.logical_not(W)\n",
    "    elif B == 'negative_sym':\n",
    "        B = (B0 / (s0 + s1)) - (B1 / (s0 + s1))\n",
    "    elif B == 'negative_asym':\n",
    "        B = (B0 / s0) - (B1 / (s0 + s1))\n",
    "    else:\n",
    "        try:\n",
    "            B = np.array(B)\n",
    "        except:\n",
    "            raise BCTParamError('unknown objective function type')\n",
    "\n",
    "        if B.shape != W.shape:\n",
    "            raise BCTParamError('objective function matrix does not match '\n",
    "                                'size of adjacency matrix')\n",
    "        if not np.allclose(B, B.T):\n",
    "            print ('Warning: objective function matrix not symmetric, '\n",
    "                   'symmetrizing')\n",
    "            B = (B + B.T) / 2\n",
    "    \n",
    "    Hnm = np.zeros((n, n))\n",
    "    for m in range(1, n + 1):\n",
    "        Hnm[:, m - 1] = np.sum(B[:, ci == m], axis=1)  # node to module degree\n",
    "    H = np.sum(Hnm, axis=1)  # node degree\n",
    "    Hm = np.sum(Hnm, axis=0)  # module degree\n",
    "\n",
    "    q0 = -np.inf\n",
    "    # compute modularity\n",
    "    q = np.sum(B[np.tile(ci, (n, 1)) == np.tile(ci, (n, 1)).T]) / s\n",
    "\n",
    "    first_iteration = True\n",
    "\n",
    "    while q - q0 > 1e-10:\n",
    "        it = 0\n",
    "        flag = True\n",
    "        while flag:\n",
    "            it += 1\n",
    "            if it > 1000:\n",
    "                raise BCTParamError('Modularity infinite loop style G. '\n",
    "                                    'Please contact the developer.')\n",
    "            flag = False\n",
    "            for u in rng.permutation(n):\n",
    "                ma = Mb[u] - 1\n",
    "                dQ = Hnm[u, :] - Hnm[u, ma] + B[u, u]  # algorithm condition\n",
    "                dQ[ma] = 0\n",
    "\n",
    "                max_dq = np.max(dQ)\n",
    "                if max_dq > 1e-10:\n",
    "                    flag = True\n",
    "                    mb = np.argmax(dQ)\n",
    "\n",
    "                    Hnm[:, mb] += B[:, u]\n",
    "                    Hnm[:, ma] -= B[:, u]  # change node-to-module strengths\n",
    "\n",
    "                    Hm[mb] += H[u]\n",
    "                    Hm[ma] -= H[u]  # change module strengths\n",
    "\n",
    "                    Mb[u] = mb + 1\n",
    "\n",
    "        _, Mb = np.unique(Mb, return_inverse=True)\n",
    "        Mb += 1\n",
    "\n",
    "        M0 = ci.copy()\n",
    "        if first_iteration:\n",
    "            ci = Mb.copy()\n",
    "            first_iteration = False\n",
    "        else:\n",
    "            for u in range(1, n + 1):\n",
    "                ci[M0 == u] = Mb[u - 1]  # assign new modules\n",
    "\n",
    "        n = np.max(Mb)\n",
    "        b1 = np.zeros((n, n))\n",
    "        for i in range(1, n + 1):\n",
    "            for j in range(i, n + 1):\n",
    "                # pool weights of nodes in same module\n",
    "                bm = np.sum(B[np.ix_(Mb == i, Mb == j)])\n",
    "                b1[i - 1, j - 1] = bm\n",
    "                b1[j - 1, i - 1] = bm\n",
    "        B = b1.copy()\n",
    "\n",
    "        Mb = np.arange(1, n + 1)\n",
    "        Hnm = B.copy()\n",
    "        H = np.sum(B, axis=0)\n",
    "        Hm = H.copy()\n",
    "\n",
    "        q0 = q\n",
    "\n",
    "        q = np.trace(B)  # compute modularity\n",
    "    \n",
    "    # Workaround to normalize\n",
    "    if not renormalize:\n",
    "        return ci, q/s\n",
    "    else:\n",
    "        return ci, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45112dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_proportional(W, p, copy=True):\n",
    "    '''\n",
    "    This function \"thresholds\" the connectivity matrix by preserving a\n",
    "    proportion p (0<p<1) of the strongest weights. All other weights, and\n",
    "    all weights on the main diagonal (self-self connections) are set to 0.\n",
    "    If copy is not set, this function will *modify W in place.*\n",
    "    Parameters\n",
    "    ----------\n",
    "    W : np.ndarray\n",
    "        weighted connectivity matrix\n",
    "    p : float\n",
    "        proportional weight threshold (0<p<1)\n",
    "    copy : bool\n",
    "        if True, returns a copy of the matrix. Otherwise, modifies the matrix\n",
    "        in place. Default value=True.\n",
    "    Returns\n",
    "    -------\n",
    "    W : np.ndarray\n",
    "        thresholded connectivity matrix\n",
    "    Notes\n",
    "    -----\n",
    "    The proportion of elements set to 0 is a fraction of all elements\n",
    "    in the matrix, whether or not they are already 0. That is, this function\n",
    "    has the following behavior:\n",
    "    >> x = np.random.random_sample((10,10))\n",
    "    >> x_25 = threshold_proportional(x, .25)\n",
    "    >> np.size(np.where(x_25)) #note this double counts each nonzero element\n",
    "    46\n",
    "    >> x_125 = threshold_proportional(x, .125)\n",
    "    >> np.size(np.where(x_125))\n",
    "    22\n",
    "    >> x_test = threshold_proportional(x_25, .5)\n",
    "    >> np.size(np.where(x_test))\n",
    "    46\n",
    "    That is, the 50% thresholding of x_25 does nothing because >=50% of the\n",
    "    elements in x_25 are aleady <=0. This behavior is the same as in BCT. Be\n",
    "    careful with matrices that are both signed and sparse.\n",
    "    Authors:\n",
    "        Olaf Sporns\n",
    "        Mikail Rubinov\n",
    "        Yusuke Adachi\n",
    "        Andrea Avena\n",
    "        Danielle Bassett\n",
    "        Richard Betzel\n",
    "        Joaquin Goni\n",
    "        Alexandros Goulas\n",
    "        Patric Hagmann\n",
    "        Christopher Honey\n",
    "        Martijn van den Heuvel\n",
    "        Rolf Kotter\n",
    "        Jonathan Power\n",
    "        Murray Shanahan\n",
    "        Andrew Zalesky\n",
    "    '''\n",
    "    if copy:\n",
    "        W = W.copy()\n",
    "    n = len(W) # number of nodes\n",
    "    np.fill_diagonal(W, 0) # clear diagonal\n",
    "\n",
    "    if np.allclose(W, W.T): # if symmetric matrix\n",
    "        W[np.tril_indices(n)] = 0 # ensure symmetry is preserved\n",
    "        ud = 2 # halve number of removed links\n",
    "    else:\n",
    "        ud = 1\n",
    "\n",
    "    ind = np.where(W) # find all links\n",
    "\n",
    "    I = np.argsort(W[ind])[::-1] # sort indices by magnitude\n",
    "\n",
    "    en = int(teachers_round((n * n - n) * p / ud)) # number of links to be preserved\n",
    "\n",
    "    W[(ind[0][I][en:], ind[1][I][en:])] = 0  # apply threshold\n",
    "    #W[np.ix_(ind[0][I][en:], ind[1][I][en:])]=0\n",
    "\n",
    "    if ud == 2: # if symmetric matrix\n",
    "        W[:, :] = W + W.T # reconstruct symmetry\n",
    "\n",
    "    return W"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
