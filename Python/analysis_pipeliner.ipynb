{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02720e8e-1955-4c33-9cac-8c0063fd7f58",
   "metadata": {},
   "source": [
    "## Select folders for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f61ddf17-918a-4167-92e0-58e685fd4bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data paths:\n",
      "D:/imaging/jm/jm038\n"
     ]
    }
   ],
   "source": [
    "# Initial folder for selection\n",
    "initial_folder = 'D:/imaging/jm/'\n",
    "\n",
    "from select_multiple import prompt_user_to_select_folder\n",
    "from select_actual_folder import select_and_update_paths\n",
    "\n",
    "#selected_folders = None\n",
    "#selected_folders = prompt_user_to_select_folder(initial_folder)\n",
    "#If you prefer select paths one by one, replace the line above by the next four lines\n",
    "#selected_folders = None\n",
    "from select_one_by_one import prompt_user_to_select_one_by_one\n",
    "selected_folders = prompt_user_to_select_one_by_one(initial_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59ae3f0-0a99-4fb6-a3ee-609b844c8ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossiers uniques trouvés dans les derniers dossiers indiqués :\n",
      "1. 2024-05-01\n",
      "2. 2024-05-02\n",
      "3. 2024-05-04\n",
      "4. 2024-05-03\n",
      "5. 2024-05-06\n",
      "6. 2024-05-05\n",
      "7. 2024-04-30\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Sélectionnez le numéro du dossier que vous souhaitez ajouter :  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier sélectionné : 2024-05-01\n",
      "Chemins mis à jour :\n",
      "D:/imaging/jm\\jm038\\2024-05-01\n"
     ]
    }
   ],
   "source": [
    "updated_paths = select_and_update_paths(selected_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ba59ed-ae09-4d1e-ba5c-a2808a368e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stat Paths:\n",
      "D:/imaging/jm\\jm038\\2024-05-01\\stat.npy\n",
      "\n",
      "Iscell Paths:\n",
      "D:/imaging/jm\\jm038\\2024-05-01\\iscell.npy\n",
      "\n",
      "Error Paths:\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Initialisation des listes pour stocker les résultats\n",
    "stat_paths = []\n",
    "iscell_paths = []\n",
    "F_paths = []\n",
    "error_paths = []\n",
    "\n",
    "for k, path in enumerate(updated_paths):\n",
    "    try:\n",
    "        # Vérifie si les fichiers stat.npy et iscell.npy existent dans le chemin fourni\n",
    "        stat_file = os.path.join(path, 'stat.npy')\n",
    "        iscell_file = os.path.join(path, 'iscell.npy')\n",
    "        F_file = os.path.join(path, 'F.npy')\n",
    "\n",
    "        if os.path.exists(stat_file) and os.path.exists(iscell_file):\n",
    "            # Si les deux fichiers existent, on les ajoute aux listes correspondantes\n",
    "            stat_paths.append(stat_file)\n",
    "            F_paths.append(F_file) \n",
    "            iscell_paths.append(iscell_file)\n",
    "        else:\n",
    "            # Si l'un des fichiers manque, ajoutez le chemin aux erreurs\n",
    "            print(f\"Error: Missing file(s) in '{path}'.\")\n",
    "            error_paths.append(path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {path}: {e}\")\n",
    "        error_paths.append(path)\n",
    "\n",
    "# Résultats : affichage des fichiers trouvés ou manquants\n",
    "print(\"Stat Paths:\")\n",
    "for path in stat_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nIscell Paths:\")\n",
    "for path in iscell_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nError Paths:\")\n",
    "for path in error_paths:\n",
    "    print(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21f6571e-b3a2-471f-b1d0-ec01fe1152f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for k, path in enumerate(updated_paths):\n",
    "    stat = np.load(stat_paths[k], allow_pickle=True)\n",
    "    F = np.load(F_paths[k], allow_pickle=True)\n",
    "    iscell = np.load(iscell_paths[k], allow_pickle=True)\n",
    "    ncells = np.sum(iscell[:, 0] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a688164-e75d-487c-949c-77c8f0fe9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = F[iscell[:, 1] > 0, :].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c539aa2c-6e44-4fa8-8c74-561dcb25ab53",
   "metadata": {},
   "source": [
    "## Do some analysis on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fc3acc-36d6-4b5f-aece-7e6c799ff190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store results\n",
    "ncell_list = []\n",
    "num_sces_list = []\n",
    "sce_n_cells_threshold_list = []\n",
    "sce_frequencies = []\n",
    "avg_active_cell_list = []\n",
    "ratio_list = []\n",
    "avg_frequency_of_activity_list = []\n",
    "avg_isis_list = []\n",
    "\n",
    "num_clusters_list = []\n",
    "all_cells_per_cluster = []\n",
    "avg_active_cells_not_in_SCEs_list = []\n",
    "\n",
    "cell_sizes_mean_list = []\n",
    "cell_sizes_std_list = []\n",
    "avg_spike_frequency_list = []\n",
    "\n",
    "# Main loop over valid paths\n",
    "for k, path in enumerate(updated_paths):\n",
    "\n",
    "    try: \n",
    "        # Load SCE and clustering data\n",
    "        try:\n",
    "            data_SCEs = scipy.io.loadmat(os.path.join(path, 'results.mat'))\n",
    "            data_clustering = scipy.io.loadmat(os.path.join(path, 'results_clustering.mat'))\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error loading .mat files: {str(e)}\")\n",
    "\n",
    "        # Number of cells\n",
    "        try:\n",
    "            F = data_SCEs['F']\n",
    "            NCell, Nz = F.shape\n",
    "            ncell_list.append(NCell)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing F matrix: {str(e)}\")\n",
    "\n",
    "        # Threshold for SCEs detection\n",
    "        try:\n",
    "            sce_n_cells_threshold = data_SCEs['sce_n_cells_threshold'][0][0]\n",
    "            sce_n_cells_threshold_list.append(sce_n_cells_threshold)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing sce_n_cells_threshold: {str(e)}\")\n",
    "            \n",
    "        # Number of SCEs\n",
    "        try:\n",
    "            TRace = data_SCEs['TRace']\n",
    "            TRace = TRace.flatten()  # Flatten to 1D if necessary\n",
    "            num_sces = len(TRace)\n",
    "            num_sces_list.append(num_sces)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing TRace and SCE metrics: {str(e)}\")\n",
    "\n",
    "        # SCE frequency in minutes\n",
    "        try:\n",
    "            nb_seconds = Nz / sampling_rate\n",
    "            sce_frequency_seconds = num_sces / nb_seconds\n",
    "            sce_frequency_minutes = sce_frequency_seconds * 60\n",
    "            sce_frequencies.append(sce_frequency_minutes)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating SCE frequency: {str(e)}\")\n",
    "        \n",
    "        # Inter-SCEs time in minutes\n",
    "        try:\n",
    "            if len(TRace) > 1:  # Ensure there's more than one event to calculate intervals\n",
    "                isis = np.diff(TRace)\n",
    "                isis_minutes = (isis / nb_seconds) * 60\n",
    "                mean_isis = np.mean(isis_minutes)\n",
    "                avg_isis_list.append(mean_isis)\n",
    "            else:\n",
    "                avg_isis_list.append(None)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating Interspike Intervals (ISIs): {str(e)}\")\n",
    "        \n",
    "        # Average number of active cells in SCEs\n",
    "        try:\n",
    "            Race = data_SCEs['Race']\n",
    "            if Race.shape[1] >= num_sces:  # Ensure correct indexing\n",
    "                avg_active_cell_SCEs = np.mean([Race[:, i].sum() for i in range(num_sces)])\n",
    "                avg_active_cell_list.append(avg_active_cell_SCEs)\n",
    "            else:\n",
    "                avg_active_cell_list.append(None)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating average number of active cells: {str(e)}\")\n",
    "\n",
    "        # Frequency of activity\n",
    "        try:\n",
    "            Raster = data_SCEs['Raster']\n",
    "            _, num_columns = Raster.shape\n",
    "            avg_activity = np.mean([Raster[:, i].sum() for i in range(num_columns)])\n",
    "            avg_frequency_of_activity_seconds = avg_activity / nb_seconds\n",
    "            avg_frequency_of_activity_list.append(avg_frequency_of_activity_seconds)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating frequency of activity: {str(e)}\")\n",
    "\n",
    "        # Ratio of active cells in SCEs/outside SCEs\n",
    "        try:\n",
    "            # Créez une séquence d'indices pour toutes les colonnes de Raster\n",
    "            inds = np.arange(num_columns)\n",
    "            indices_not_SCEs = np.array([i for i in inds if i not in TRace])\n",
    "        \n",
    "            if len(indices_not_in_SCEs) > 0:  # Ensure there are valid indices to compare\n",
    "                avg_active_cells_not_in_SCEs = np.mean([Raster[:, i].sum() for i in indices_not_SCEs])\n",
    "                ratio = avg_active_cell_SCEs / avg_active_cells_not_in_SCEs\n",
    "            else:\n",
    "                ratio = np.nan\n",
    "                \n",
    "            ratio_list.append(ratio)\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating ratio of active cells in SCEs/outside SCEs: {str(e)}\")\n",
    "\n",
    "        # Cell sizes calculation\n",
    "        try:\n",
    "            largeur_champ_micro = 750\n",
    "            resolution_pixels = 512\n",
    "            taille_pixel_micro = largeur_champ_micro / resolution_pixels\n",
    "            taille_pixel_micro_carré = taille_pixel_micro ** 2\n",
    "            cell_sizes_list = []\n",
    "            \n",
    "            stat = np.load(stat_paths[k], allow_pickle=True)\n",
    "            iscell = np.load(iscell_paths[k], allow_pickle=True)\n",
    "            ncells = np.sum(iscell[:, 0] == 1)\n",
    "            for n in range(ncells):\n",
    "                cellsize = stat[n]['npix']\n",
    "                cell_size_microns_squared = cellsize * taille_pixel_micro_carré\n",
    "                cell_sizes_list.append(cell_size_microns_squared)\n",
    "                \n",
    "            if cell_sizes_list:\n",
    "                cell_sizes_array = np.array(cell_sizes_list)\n",
    "                mean_cell_size = np.mean(cell_sizes_array)\n",
    "                std_cell_size = np.std(cell_sizes_array)\n",
    "                cell_sizes_mean_list.append(mean_cell_size)\n",
    "                cell_sizes_std_list.append(std_cell_size)\n",
    "            else:\n",
    "                cell_sizes_mean_list.append(None)\n",
    "                cell_sizes_std_list.append(None)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error calculating cell sizes: {str(e)}\")\n",
    "            \n",
    "\n",
    "        # Clusters number and active cells per clusters\n",
    "        try:\n",
    "            NClOK = data_clustering['NClOK'].item()  # Assuming it's a single value\n",
    "            if NClOK >= 1:\n",
    "                clusterMatrix = data_clustering['clusterMatrix']\n",
    "                num_clusters = np.unique(clusterMatrix[:, 1]).size\n",
    "                num_clusters_list.append(num_clusters)\n",
    "                \n",
    "                cells_per_cluster = [(cluster_id, np.sum(clusterMatrix[:, 1] == cluster_id)) for cluster_id in np.unique(clusterMatrix[:, 1])]\n",
    "                all_cells_per_cluster.append(cells_per_cluster)\n",
    "            else:\n",
    "                num_clusters_list.append(0)\n",
    "                all_cells_per_cluster.append(None)\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error processing clustering information: {str(e)}\")\n",
    "\n",
    "    \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {e}\")\n",
    "        # Append None for each list if file is not found\n",
    "        num_sces_list.append(None)\n",
    "        sce_n_cells_threshold_list.append(None)\n",
    "        sce_frequencies.append(None)\n",
    "        avg_active_cell_list.append(None)\n",
    "        ratio_list.append(None)\n",
    "        avg_frequency_of_activity_list.append(None)\n",
    "        avg_isis_list.append(None)\n",
    "        num_clusters_list.append(None)\n",
    "        all_cells_per_cluster.append(None)\n",
    "        cell_sizes_mean_list.append(None)\n",
    "        cell_sizes_std_list.append(None)\n",
    "        continue\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error in path {path}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e6a91-9a00-490b-9978-724fa3a56bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser une liste pour stocker les deux dernières parties des chemins\n",
    "last_two_parts = []\n",
    "\n",
    "for path in updated_paths:\n",
    "    # Remplacer tous les séparateurs par '/'\n",
    "    path = path.replace('\\\\', '/')\n",
    "    \n",
    "    # Séparer le chemin en parties\n",
    "    path_parts = path.split('/')\n",
    "    \n",
    "    # Conserver les deux dernières parties\n",
    "    if len(path_parts) >= 2:\n",
    "        last_two = '/'.join(path_parts[-2:])\n",
    "    else:\n",
    "        last_two = path  # Si le chemin est trop court, conserver le chemin entier\n",
    "    \n",
    "    # Ajouter les deux dernières parties à la liste\n",
    "    last_two_parts.append(last_two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd047d0-ce5c-4667-9cbf-53aa7994932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize the final DataFrame\n",
    "df_final = pd.DataFrame()\n",
    "\n",
    "# List to collect rows\n",
    "rows = []\n",
    "\n",
    "# Loop over each folder to populate the DataFrame\n",
    "for i in range(len(updated_paths)):\n",
    "    folder = last_two_parts[i]\n",
    "    num_cells = ncell_list[i]\n",
    "    num_sces = num_sces_list[i]\n",
    "    sce_threshold = sce_n_cells_threshold_list[i]\n",
    "    sce_freq = sce_frequencies[i]\n",
    "    avg_active_cells = avg_active_cell_list[i]\n",
    "    ratio = ratio_list[i]\n",
    "    avg_freq_activity = avg_frequency_of_activity_list[i]\n",
    "    avg_isi = avg_isis_list[i]\n",
    "    num_clusters = num_clusters_list[i]\n",
    "    cells_per_cluster = all_cells_per_cluster[i]\n",
    "    avg_cell_sizes = cell_sizes_mean_list[i]\n",
    "    std_cell_sizes = cell_sizes_std_list[i]\n",
    "\n",
    "    # Ensure that cells_per_cluster is a list\n",
    "    if cells_per_cluster is None:\n",
    "        cells_per_cluster = [(None, None)] * num_clusters\n",
    "    \n",
    "    # Create the base row for the first cluster\n",
    "    base_row = {\n",
    "        'Folder': folder,\n",
    "        'Number of cells': num_cells,\n",
    "        'Number of SCEs': num_sces,\n",
    "        'Threshold of cell numbers for SCEs detection': sce_threshold,\n",
    "        'SCE frequency (minutes)': sce_freq,\n",
    "        'Average number of cells in SCES': avg_active_cells,\n",
    "        'Ratio of number of cells in SCES/outside SCES': ratio,\n",
    "        'Averaged frequency of cell activity (Hz)': avg_freq_activity,\n",
    "        'Averaged cell sizes (microns squared)': avg_cell_sizes,\n",
    "        'Std of cell sizes (microns squared)': std_cell_sizes,\n",
    "        'Averaged time intervals between consecutive SCEs (minutes)': avg_isi,\n",
    "        'Cluster number': cells_per_cluster[0][0],\n",
    "        'Number of cells per cluster': cells_per_cluster[0][1],\n",
    "     \n",
    "    }\n",
    "\n",
    "    # Append the base row\n",
    "    rows.append(base_row)\n",
    "\n",
    "    # Add rows for the remaining clusters with only cluster-specific data\n",
    "    for j in range(1, num_clusters):\n",
    "        rows.append({\n",
    "            'Folder': '',\n",
    "            'Number of cells': '',\n",
    "            'Number of SCEs': '',\n",
    "            'Threshold of cell numbers for SCEs detection': '',\n",
    "            'SCE frequency (minutes)': '',\n",
    "            'Average number of cells in SCES': '',\n",
    "            'Ratio of number of cells in SCES/outside SCES': '',\n",
    "            'Averaged frequency of cell activity (Hz)': '',\n",
    "            'Averaged cell sizes (microns squared)': '',\n",
    "            'Std of cell sizes (microns squared)': '',\n",
    "            'Averaged time intervals between consecutive SCEs (minutes)': '',\n",
    "            'Cluster number': cells_per_cluster[j][0],\n",
    "            'Number of cells per cluster': cells_per_cluster[j][1],\n",
    "        })\n",
    "\n",
    "# Convert list of rows to DataFrame\n",
    "df_final = pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22db50e-66fb-43e0-b8ce-153e0edd1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.utils.dataframe import dataframe_to_rows\n",
    "\n",
    "# Extraire le nom du répertoire\n",
    "folder_name = os.path.basename(data_path)\n",
    "\n",
    "# Définir le chemin de sortie pour le fichier Excel\n",
    "output_file = os.path.join(PathSave, 'results_summary.xlsx')\n",
    "\n",
    "# Vérifier si le fichier Excel existe déjà\n",
    "if os.path.exists(output_file):\n",
    "    # Lire le fichier Excel existant\n",
    "    with pd.ExcelFile(output_file, engine='openpyxl') as xls:\n",
    "        # Charger toutes les feuilles existantes dans un dictionnaire de DataFrames\n",
    "        sheet_dict = {sheet_name: xls.parse(sheet_name) for sheet_name in xls.sheet_names}\n",
    "        \n",
    "    # Ajouter la nouvelle feuille au dictionnaire de DataFrames\n",
    "    sheet_dict[folder_name] = df_final\n",
    "    \n",
    "    # Écrire toutes les feuilles, y compris la nouvelle\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        for sheet_name, df in sheet_dict.items():\n",
    "            df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "else:\n",
    "    # Si le fichier n'existe pas, créer un nouveau fichier avec la feuille\n",
    "    with pd.ExcelWriter(output_file, engine='xlsxwriter') as writer:\n",
    "        df_final.to_excel(writer, sheet_name=folder_name, index=False)\n",
    "\n",
    "print(f\"Data exported successfully to {output_file} with sheet named '{folder_name}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
